{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef59cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "import pickle \n",
    "\n",
    "data_dir = './DATASET/train'\n",
    "\n",
    "categories = ['angry', 'disgust' , 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "data = []\n",
    "\n",
    "def make_data():\n",
    "\tfor category in categories:\n",
    "\t\tpath = os.path.join(data_dir, category)\n",
    "\t\tlabel = categories.index(category)\n",
    "\n",
    "\t\tfor img_name in os.listdir(path):\n",
    "\t\t\timage_path = os.path.join(path, img_name)\n",
    "\t\t\timage = cv2.imread(image_path)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\t\t\timage = cv2.resize(image, (224,224))\n",
    "\t\t\t\timage = np.array(image)\n",
    "\n",
    "\t\t\t\tdata.append([image, label])\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\tprint(len(data))\n",
    "\tpik = open('train.pickle','wb')\n",
    "\tpickle.dump(data, pik)\n",
    "\tpik.close()\n",
    "make_data()\n",
    "def load_data():\n",
    "\tpick  = open('train.pickle', 'rb')\n",
    "\tdata = pickle.load(pick)\n",
    "\n",
    "\tpick.close()\n",
    "\n",
    "\t#np.random(data)\n",
    "\n",
    "\tfeature = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor img, label in data:\n",
    "\t\tfeature.append(img)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "\tfeature = np.array(feature, dtype = np.float32)\n",
    "\tfeature = feature/ 255.\n",
    "\n",
    "\tlabels = np.array(labels)\n",
    "\n",
    "\treturn [feature, labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe16a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " tf.nn.max_pool2d (TFOpLambd  (None, 112, 112, 64)     0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " tf.nn.max_pool2d_1 (TFOpLam  (None, 56, 56, 128)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_4 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " tf.nn.max_pool2d_2 (TFOpLam  (None, 28, 28, 256)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_4 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " tf.nn.max_pool2d_3 (TFOpLam  (None, 14, 14, 512)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_4 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " tf.nn.max_pool2d_4 (TFOpLam  (None, 7, 7, 512)        0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 256)               6422784   \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 5)                 645       \n",
      "                                                                 \n",
      " tf.nn.softmax (TFOpLambda)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,480,709\n",
      "Trainable params: 26,480,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "input_layer = tf.keras.layers.Input([224,224,3])\n",
    "#block1 \n",
    "conv1_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3],strides=[1,1], \n",
    "\tpadding='same',activation='relu', name='conv1_1')(input_layer)\n",
    "\n",
    "conv1_2 = tf.keras.layers.Conv2D(filters= 64, kernel_size=[3,3], strides= [1,1],\n",
    "\tpadding='same',activation='relu', name='conv1_2')(conv1_1)\n",
    "\n",
    "pool1_1 = tf.nn.max_pool(conv1_2, ksize = [1,2,2,1],strides=[1,2,2,1],\n",
    "\tpadding='SAME', name='pool1_1')\n",
    "\n",
    "\n",
    "#block 2\n",
    "conv2_1 = tf.keras.layers.Conv2D(filters= 128, kernel_size=[3,3],strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv2_1')(pool1_1)\n",
    "\n",
    "\n",
    "conv2_2 = tf.keras.layers.Conv2D(filters = 128, kernel_size=[3,3], strides = [1,1],\n",
    "\tpadding='same', activation='relu', name='conv2_2')(conv2_1)\n",
    "\n",
    "\n",
    "pool2_1 = tf.nn.max_pool(conv2_2, ksize = [1,2,2,1], strides= [1,2,2,1],\n",
    "\tpadding='SAME', name='pool2_1')\n",
    "\n",
    "\n",
    "\n",
    "#block3 \n",
    "\n",
    "conv3_1 = tf.keras.layers.Conv2D(filters= 256, kernel_size=[3,3], strides = [1,1],\n",
    "\tpadding='same', activation='relu', name='conv3_1')(pool2_1)\n",
    "\n",
    "conv3_2 = tf.keras.layers.Conv2D(filters = 256, kernel_size=[3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv3_2')(conv3_1)\n",
    "\n",
    "conv3_3 = tf.keras.layers.Conv2D(filters = 256, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv3_3')(conv3_2)\n",
    "\n",
    "\n",
    "conv3_4 = tf.keras.layers.Conv2D(filters = 256, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv3_4')(conv3_3)\n",
    "\n",
    "\n",
    "pool3_1 = tf.nn.max_pool(conv3_4, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
    "\tpadding=\"SAME\",name='pool3_1')\n",
    "\n",
    "#block4 \n",
    "\n",
    "conv4_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv4_1')(pool3_1)\n",
    "\n",
    "\n",
    "conv4_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv4_2')(conv4_1)\n",
    "\n",
    "\n",
    "conv4_3 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv4_3')(conv4_2)\n",
    "\n",
    "\n",
    "conv4_4 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv4_4')(conv4_3)\n",
    "\n",
    "pool4_1 = tf.nn.max_pool(conv4_4, ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "\tpadding='SAME', name='pool4_1')\n",
    "\n",
    "#block5\n",
    "\n",
    "\n",
    "conv5_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv5_1')(pool4_1)\n",
    "\n",
    "conv5_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv5_2')(conv5_1)\n",
    "\n",
    "conv5_3 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv5_3')(conv5_2)\n",
    "\n",
    "conv5_4 = tf.keras.layers.Conv2D(filters = 512, kernel_size= [3,3], strides=[1,1],\n",
    "\tpadding='same', activation='relu', name='conv5_4')(conv5_3)\n",
    "\n",
    "pool5_1 = tf.nn.max_pool(conv5_4, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
    "\tpadding='SAME', name='pool5_1')\n",
    "\n",
    "\n",
    "\n",
    "flatten  = tf.keras.layers.Flatten()(pool5_1)\n",
    "\n",
    "fc6 = tf.keras.layers.Dense(units=256, name='fc6', activation='relu')(flatten)\n",
    "fc7 = tf.keras.layers.Dense(units=128, name='fc7', activation='relu')(fc6)\n",
    "fc8 = tf.keras.layers.Dense(units=5, name='fc8',activation=None)(fc7)\n",
    "\n",
    "\n",
    "prob = tf.nn.softmax(fc8)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(input_layer, prob)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3010bae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.1 GiB for an array with shape (28709, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split  \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m \n\u001b[1;32m----> 6\u001b[0m feature, label \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m categories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhappy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(feature, label, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \tfeature\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     51\u001b[0m \tlabels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m---> 53\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m\n\u001b[0;32m     56\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.1 GiB for an array with shape (28709, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "#from utils import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import tensorflow as tf \n",
    "\n",
    "feature, label = load_data()\n",
    "categories = ['angry', 'disgust', 'fear','happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=0.1, shuffle=True)\n",
    "\n",
    "x_train, x_test = tf.cast(x_train, tf.float32), tf.cast(x_test, tf.float32)\n",
    "\n",
    "train_dataset= tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_dataset = train_dataset.batch(batch_size= 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('myVggModel.h5')\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adadelta()\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tpredictions = model(images, training= True)\n",
    "\t\tloss = loss_object(y_true= labels, y_pred= predictions)\n",
    "\n",
    "\tgradients = tape.gradient(loss, model.trainable_variables)\n",
    "\toptimizer.apply_gradients(grads_and_vars = zip(gradients, model.trainable_variables))\n",
    "\n",
    "\ttrain_loss(loss)\n",
    "\ttrain_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "\ttrain_loss.reset_states()\n",
    "\ttrain_accuracy.reset_states()\n",
    "\n",
    "\tstep = 0\n",
    "\n",
    "\tfor images, labels in train_dataset:\n",
    "\t\tstep+=1 \n",
    "\t\ttrain_step(images, labels)\n",
    "\n",
    "\t\tif step%10 ==0:\n",
    "\n",
    "\t\t\tprint('=> epoch: %i, loss: %.4f, train_accuracy: %.4f'%(epoch+1,\n",
    "\t\t\t\ttrain_loss.result(), train_accuracy.result()))\n",
    "model.save('myVggModel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cad37c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.1 GiB for an array with shape (28709, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 7\u001b[0m feature, label \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(feature, label, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m categories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhappy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \tfeature\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     51\u001b[0m \tlabels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m---> 53\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m\n\u001b[0;32m     56\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.1 GiB for an array with shape (28709, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "#from utils import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "feature, label = load_data()\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=0.1, shuffle=True)\n",
    "\n",
    "categories = ['angry', 'disgust', 'fear','happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "model = tf.keras.models.load_model('myVggModel.h5')\n",
    "\n",
    "\n",
    "prediction = model(x_test[0:9])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in range(9):\n",
    "\tplt.subplot(3,3,i+1)\n",
    "\tplt.imshow(x_test[i])\n",
    "\tplt.xlabel('Pedicted:%s\\n Actual: %s'%(categories[np.argmax(prediction[i])],\n",
    "\t\tcategories[y_test[i]]))\n",
    "\n",
    "\tplt.xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb6c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
